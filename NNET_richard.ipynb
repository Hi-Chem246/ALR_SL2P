{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ALR Client Side\n",
    "\n",
    "This notebook is a copy similar to ALR_Client_Side found in:\n",
    "https://github.com/rfernand387/ALR_Earth_Engine/blob/master/ALR_Client_Side.ipynb\n",
    "\n",
    "The input image is assumed to be in the format generated by SL2P10_control.ipynb:\n",
    "https://github.com/kateharvey/Sentinel2_ALR/blob/main/shared/SL2P10_control.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl ; from sklearn import preprocessing ; from sklearn import linear_model\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "import geemap\n",
    "import image_bands as ib\n",
    "import feature_collections as fc\n",
    "\n",
    "# import custom module\n",
    "import ALR_functions_richard as alr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jupyter notebook below has code blocks required to apply a  neural network that is uploaded to Earth Engine to an image.  Make sure the image has the correct bands that the network used when it was calibrated (including the same scaling).   I found the solution slow so maybe try it on a small image subset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the trimmed data is processed then in a neural network created using tensorflow to find nonlinear relationships between the predictor and the response. Earth Engine does not have this functionality (for free) to generate neural network based models.\n",
    "\n",
    "Here we also see how the server side in the Earth Engine API is completely separate from the client side on the local machine. We need\n",
    "to export our trimmed data as a CSV to a google drive which is synced into the \"gdrive\" folder in our local machine using the \n",
    "Backup and Sync software or using google-drive-ocamlfuse on Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more robust way to check if the data has been exported properly, we can use a wait loop to check on our local machine until the exported data file exists in the synced \"gdrive\" folder\n",
    "\n",
    "From here on out, all of the processing is done using your local hardware and packages, so it may be helpful to use a powerful machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_layer(feature):\n",
    "    feature = ee.Feature(feature)\n",
    "    prev_layer_size = feature.getNumber(\"prev_layer_size\")\n",
    "    num_nodes = feature.getNumber(\"num_nodes\")\n",
    "    node_size = prev_layer_size.subtract(1)\n",
    "    activation = feature.getString(\"activation\")\n",
    "    \n",
    "    node_collection = ee.ImageCollection(ee.List.sequence(1, num_nodes)\\\n",
    "                        .map(lambda node: ee.ImageCollection(ee.List.sequence(ee.Number(node).toInt(), ee.Number(node)\\\n",
    "                                    .toInt().add(node_size.multiply(num_nodes)), num_nodes)\\\n",
    "                        .map(lambda index: ee.Image(feature.getNumber(ee.Number(index).toInt())))).toBands()\\\n",
    "                        .set({\"bias\": feature.getNumber(ee.Number(node).toInt().add(prev_layer_size.multiply(num_nodes)))})))\n",
    "    \n",
    "    return ee.List([node_collection, activation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse neural net from gee asset\n",
    "nnet = ee.FeatureCollection(\"users/hlahiouel/nnet\")\n",
    "nnet_inputs = nnet.filter(ee.Filter.eq(\"layer_num\", 0)).first()\n",
    "num_inputs = nnet_inputs.getNumber(\"num_nodes\")\n",
    "nnet = nnet.filterBounds(ee.Geometry.Point([0,0]))\n",
    "layer_list = nnet.sort(\"layer_num\").toList(nnet.size())\n",
    "neural_net = layer_list.map(parse_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_OPTIONS = {\n",
    "    # Sentinel 2 using 20 m bands:\n",
    "    'COPERNICUS/S2_SR': {\n",
    "      \"name\": 'COPERNICUS/S2_SR',\n",
    "      \"description\": 'Sentinel 2A',\n",
    "      \"Cloudcover\": 'CLOUDY_PIXEL_PERCENTAGE',\n",
    "      \"Watercover\": 'WATER_PERCENTAGE',\n",
    "      \"sza\": 'MEAN_SOLAR_ZENITH_ANGLE',\n",
    "      \"vza\": 'MEAN_INCIDENCE_ZENITH_ANGLE_B8A',\n",
    "      \"saa\": 'MEAN_SOLAR_AZIMUTH_ANGLE', \n",
    "      \"vaa\": 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B8A',\n",
    "      \"VIS_OPTIONS\": 'VIS_OPTIONS',\n",
    "      \"Collection_SL2P\": ee.FeatureCollection(fc.s2_createFeatureCollection_estimates()),\n",
    "      \"Collection_SL2Perrors\": ee.FeatureCollection(fc.s2_createFeatureCollection_errors()),  \n",
    "      \"sl2pDomain\": ee.FeatureCollection(fc.s2_createFeatureCollection_domains()),\n",
    "      \"Network_Ind\": ee.FeatureCollection(fc.s2_createFeatureCollection_Network_Ind()),\n",
    "      \"partition\": ee.ImageCollection(fc.s2_createImageCollection_partition()),\n",
    "      \"legend\": ee.FeatureCollection(fc.s2_createFeatureCollection_legend()),\n",
    "      \"numVariables\": 7\n",
    "    },\n",
    "    'LANDSAT/LC08/C01/T1_SR': {\n",
    "      \"name\": 'LANDSAT/LC08/C01/T1_SR',\n",
    "      \"description\": 'LANDSAT 8',\n",
    "      \"Cloudcover\": 'CLOUD_COVER_LAND',\n",
    "      \"Watercover\": 'CLOUD_COVER',\n",
    "      \"sza\": 'SOLAR_ZENITH_ANGLE',\n",
    "      \"vza\": 'SOLAR_ZENITH_ANGLE',\n",
    "      \"saa\": 'SOLAR_AZIMUTH_ANGLE', \n",
    "      \"vaa\": 'SOLAR_AZIMUTH_ANGLE',\n",
    "      \"VIS_OPTIONS\": 'VIS_OPTIONS',\n",
    "      \"Collection_SL2P\": ee.FeatureCollection(fc.l8_createFeatureCollection_estimates()),\n",
    "      \"Collection_SL2Perrors\": ee.FeatureCollection(fc.l8_createFeatureCollection_errors()),\n",
    "      \"sl2pDomain\": ee.FeatureCollection(fc.l8_createFeatureCollection_domains()),\n",
    "      \"Network_Ind\": ee.FeatureCollection(fc.l8_createFeatureCollection_Network_Ind()),\n",
    "      \"partition\": ee.ImageCollection(fc.l8_createImageCollection_partition()),\n",
    "      \"legend\": ee.FeatureCollection(fc.l8_createFeatureCollection_legend()),\n",
    "      \"numVariables\": 7\n",
    "    }\n",
    "}\n",
    "\n",
    "VIS_OPTIONS = {\n",
    "    'fAPAR': {\n",
    "        \"COPERNICUS/S2_SR\": {\n",
    "            \"Name\": 'fAPAR',\n",
    "            \"errorName\": 'errorfAPAR',\n",
    "            \"maskName\": 'maskfAPAR',\n",
    "            \"description\": 'Fraction of absorbed photosynthetically active radiation',\n",
    "            \"variable\": 2,\n",
    "            \"inputBands\":      ['cosVZA', 'cosSZA', 'cosRAA', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8A', 'B11', 'B12'],\n",
    "            \"inputScaling\":    [0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001],\n",
    "            \"outmin\": (ee.Image(ee.Array([[0]]))),\n",
    "            \"outmax\": (ee.Image(ee.Array([[1]])))\n",
    "        }\n",
    "    },\n",
    "    'fCOVER': {\n",
    "        \"COPERNICUS/S2_SR\": {\n",
    "            \"Name\": 'fCOVER',\n",
    "            \"errorName\": 'errorfCOVER',\n",
    "            \"maskName\": 'maskfCOVER',\n",
    "            \"description\": 'Fraction of canopy cover',\n",
    "            \"variable\": 3,\n",
    "            \"inputBands\":      ['cosVZA', 'cosSZA', 'cosRAA', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8A', 'B11', 'B12'],\n",
    "            \"inputScaling\":    [0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001],\n",
    "            \"outmin\": (ee.Image(ee.Array([[0]]))),\n",
    "            \"outmax\": (ee.Image(ee.Array([[1]]))) \n",
    "        }\n",
    "    },\n",
    "    'LAI': {\n",
    "        \"COPERNICUS/S2_SR\": {\n",
    "            \"Name\": 'LAI',\n",
    "            \"errorName\": 'errorLAI',\n",
    "            \"maskName\": 'maskLAI',\n",
    "            \"description\": 'Leaf area index',\n",
    "            \"variable\": 1,\n",
    "            \"inputBands\":      ['cosVZA', 'cosSZA', 'cosRAA', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8A', 'B11', 'B12'],\n",
    "            \"inputScaling\":    [0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001],\n",
    "            \"outmin\": (ee.Image(ee.Array([[0]]))),\n",
    "            \"outmax\": (ee.Image(ee.Array([[1]])))\n",
    "        }\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the networks\n",
    "colName = 'COPERNICUS/S2_SR'\n",
    "colOptions = COLLECTION_OPTIONS[colName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputImage = ee.Image('COPERNICUS/S2_SR/20200811T164849_20200811T165525_T16UEA')\n",
    "\n",
    "mapBounds = inputImage.geometry()\n",
    "\n",
    "input_collection = ee.ImageCollection(inputImage) \\\n",
    "                         .map(lambda image: ib.addDate(image)) \\\n",
    "                         .map(lambda image: image.clip(mapBounds)) \\\n",
    "                         .map(lambda image: ib.s2MaskClear(image)) \\\n",
    "                         .map(lambda image: ib.s2MaskLand(image)) \\\n",
    "                         .map(lambda image: ib.addS2Geometry(colOptions, image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputImage = input_collection.first()\n",
    "\n",
    "input_nvdi = (inputImage.select('B8').subtract(inputImage.select('B4'))).divide(inputImage.select('B8').add(inputImage.select('B4')).add(ee.Image.constant(0.01))).rename('NVDI')\n",
    "\n",
    "inputImage = inputImage.addBands(input_nvdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAI_inputs = ['B3','B4', 'B5', 'B6', 'B7', 'B8A', 'B11', 'B12','cosVZA', 'cosSZA', 'cosRAA', 'NVDI']\n",
    "\n",
    "select_features = ['B0', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'cosVZA', 'cosSZA', 'cosRAA', 'NVDI']\n",
    "\n",
    "inputImage = inputImage.select(LAI_inputs).rename(select_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputImage.bandNames().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input image for network and apply network\n",
    "# make sure input bands match inputs when network was trained, including any scaling\n",
    "nnet_inputs = inputImage.select(select_features)\n",
    "#print(inputImage.bandNames().getInfo())\n",
    "#prediction_data = ee.Image(neural_net.iterate(alr.apply_nnet, nnet_inputs)).rename(\"NNET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display result using geemap\n",
    "Map = geemap.Map(center=[40,-100], zoom=4)\n",
    "Map\n",
    "Map.addLayer(prediction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayer(nnet_inputs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LAI_FAPAR_FCOVER_Prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
