{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78278b9-2b56-4b42-a8b5-a6be7becf1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only the useful inputs are used in the Euclidean distance calculation\n",
    "# only LAI is looked at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b18ae01-4c96-4dba-a89e-7e364d281ae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the necessary packages and libraries #\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import numpy.matlib\n",
    "import pandas \n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "import tensorflow\n",
    "from tensorflow import keras \n",
    "import os\n",
    "from sklearn.neighbors import DistanceMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666da758-0a8e-4df2-a5a7-b8f840df67f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the precision of the data in the Pandas Dataframes \n",
    "\n",
    "pandas.set_option(\"precision\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0781966-289a-4b9e-b3a8-ccf7ba6e9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes any Tensorflow warnings \n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c31e1-123c-4e7e-a678-b343889245a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MatLab data #\n",
    "\n",
    "matlabData = sio.loadmat(file_name='./data/s2_sl2p_uniform_10_replicates_sobol_prosail_inout.mat', variable_names=['Input', 'Output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e2f970-8a5b-4da9-8147-de6aed1c96c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the input and output data #\n",
    "\n",
    "bands = pandas.DataFrame(data=matlabData['Input']['Rho_Toc'][0][0])\n",
    "angles = pandas.DataFrame(data=matlabData['Input']['Angles'][0][0])\n",
    "LAI = pandas.Series(data=matlabData['Output']['LAI'][0][0].flatten())\n",
    "FAPAR = pandas.Series(data=matlabData['Output']['FAPAR'][0][0].flatten())\n",
    "FCOVER = pandas.Series(data=matlabData['Output']['FCOVER'][0][0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e04537-7d8e-43ee-9bc6-9ab33bb56f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the calibration data #\n",
    "\n",
    "cal_data = pandas.concat([bands, angles, LAI, FAPAR, FCOVER], axis=1, join='outer')\n",
    "\n",
    "cal_data.columns = ['B0', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'A1', 'A2', 'A3', 'LAI', 'FAPAR', 'FCOVER']\n",
    "\n",
    "cal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e0d872-4da6-41f2-bf21-fbbb144c075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the calibration data #\n",
    "\n",
    "cal_data_scaled = pandas.DataFrame(sklearn.preprocessing.StandardScaler().fit_transform(cal_data))\n",
    "\n",
    "cal_data_scaled.columns = ['B0', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'A1', 'A2', 'A3', 'LAI', 'FAPAR', 'FCOVER']\n",
    "\n",
    "cal_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7fac25-0dbe-4c7e-8a85-40a3145e79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subset id's #\n",
    "\n",
    "rep = 10\n",
    "\n",
    "subsets = numpy.arange(0, int(cal_data_scaled.shape[0]/10))\n",
    "\n",
    "subset_ids = numpy.matlib.repmat(subsets, 1, rep)\n",
    "\n",
    "cal_data_scaled['subset_id'] = subset_ids[0]\n",
    "\n",
    "cal_data_scaled.columns = ['B0', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'A1', 'A2', 'A3', 'LAI', 'FAPAR', 'FCOVER', 'subset_id']\n",
    "\n",
    "cal_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67445684-69b5-49c6-8a10-42222408778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data to create reference database # \n",
    "\n",
    "ref_data = cal_data_scaled.sample(n=100, ignore_index=False)\n",
    "\n",
    "ref_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4be0f-e434-4924-954b-b892285c4256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of indices to remove from the calibration database #\n",
    "\n",
    "index_list = ref_data.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce18300-eb70-41dd-ab61-54ccc4ec4b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resets the indices in the reference data so that they start from zero\n",
    "\n",
    "ref_data = ref_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb0feca-4214-4701-8ac9-0cfc5151bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes the indices from calibration database that are in the reference database #\n",
    "\n",
    "cal_data_scaled = cal_data_scaled.drop(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e836301d-029d-41c9-9865-31b5cfd71d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resets the indices in the calibration data so that they start from zero\n",
    "\n",
    "cal_data_scaled = cal_data_scaled.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecefc8d0-ad19-41d9-9208-72adccd547cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the training and validation sets from the calibration data\n",
    "\n",
    "features_training, features_valid = sklearn.model_selection.train_test_split(cal_data_scaled, test_size=0.3, train_size=0.7, random_state=None, shuffle=True, stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a9463-f8fa-4884-9997-198fca519843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resets the indices in the training data so that they start from zero\n",
    "\n",
    "features_training = features_training.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138925fc-d31c-4385-8db6-0b4311926ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resets the indices in the validation data so that they start from zero\n",
    "\n",
    "features_valid = features_valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65697f96-b91e-4ccf-be4a-9a8ce41da78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the LAI, FAPAR, and FCOVER data to be used for training\n",
    "\n",
    "LAI_feature_training = features_training['LAI']\n",
    "FAPAR_feature_training = features_training['FAPAR']\n",
    "FCOVER_feature_training = features_training['FCOVER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d6d10b-3207-48c9-8daa-a6325e295fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the LAI, FAPAR, and FCOVER data to be used for validation\n",
    "\n",
    "LAI_feature_valid = features_valid['LAI']\n",
    "FAPAR_feature_valid = features_valid['FAPAR']\n",
    "FCOVER_feature_valid = features_valid['FCOVER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eef993f-aea4-4a6b-b0c2-faff7b2b6708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes that isn't needed for training and validation \n",
    "features_training = features_training.drop(['LAI', 'FAPAR', 'FCOVER','subset_id'], axis=1)\n",
    "features_valid = features_valid.drop(['LAI', 'FAPAR', 'FCOVER','subset_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb992d7-edf6-4687-bb25-f1771e58d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a model for LAI, FAPAR, and FCOVER using LARs regression \n",
    "\n",
    "LAI_feature_model = sklearn.linear_model.Lars(n_nonzero_coefs=4)\n",
    "LAI_feature_model = LAI_feature_model.fit(features_training, LAI_feature_training)\n",
    "\n",
    "FAPAR_feature_model = sklearn.linear_model.Lars(n_nonzero_coefs=4)\n",
    "FAPAR_feature_model = FAPAR_feature_model.fit(features_training, FAPAR_feature_training)\n",
    "\n",
    "FCOVER_feature_model = sklearn.linear_model.Lars(n_nonzero_coefs=3)\n",
    "FCOVER_feature_model = FCOVER_feature_model.fit(features_training, FCOVER_feature_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6ce69-3803-4c97-a9d0-8871a02cb131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes predictions on the validation data using the LARS models\n",
    "\n",
    "LAI_feature_predicted = pandas.Series(LAI_feature_model.predict(features_valid))\n",
    "FAPAR_feature_predicted = pandas.Series(FAPAR_feature_model.predict(features_valid))\n",
    "FCOVER_feature_predicted = pandas.Series(FCOVER_feature_model.predict(features_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21506554-6ee6-48f5-ba92-b6b6404a8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the features from the LARS Model\n",
    "\n",
    "LAI_features = numpy.nonzero(LAI_feature_model.coef_)[0]\n",
    "FAPAR_features = numpy.nonzero(FAPAR_feature_model.coef_)[0]\n",
    "FCOVER_features = numpy.nonzero(FCOVER_feature_model.coef_)[0]\n",
    "\n",
    "LAI_features = features_valid.columns[LAI_features]\n",
    "print(LAI_features)\n",
    "FAPAR_features = features_valid.columns[FAPAR_features]\n",
    "print(FAPAR_features)\n",
    "FCOVER_features = features_valid.columns[FCOVER_features]\n",
    "print(FCOVER_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb231d-fc95-4b7e-8778-188359f3b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates arrays containing the calibration and reference data \n",
    "\n",
    "ref_array = numpy.array(ref_data[LAI_features])\n",
    "\n",
    "cal_array = numpy.array(cal_data_scaled[LAI_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5f9dd-efff-46de-8dd6-3c2b4ea19434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calls function from sci-kit learn for calculating the euclidean distance \n",
    "\n",
    "dist = DistanceMetric.get_metric('euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0175af-4b35-4e37-975f-25bbcc0ec93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the probability for each sample in the calibration data\n",
    "\n",
    "probs = numpy.exp(-numpy.amin(dist.pairwise(cal_array,ref_array),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f498e2c-9f6a-4d59-a48f-d17e364ea7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the probability column in the calibration database #\n",
    "\n",
    "cal_data_scaled['prob'] = probs \n",
    "\n",
    "cal_data_scaled.columns = ['B0', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'A1', 'A2', 'A3', 'LAI', 'FAPAR', 'FCOVER', 'subset_id', 'prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc47387d-52bd-4d43-9f16-32a664052e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ba6f6-e8c9-4a2e-aacc-a7579fbb7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize the probabilities \n",
    "\n",
    "def normalize(data):\n",
    "    sum_prob = sum(data['prob'])\n",
    "    data['prob'] = data['prob']/sum_prob\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34571ec3-5766-4afb-8dc9-7b7e095e1616",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(cal_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394bbefb-e504-42aa-aa10-13da187324b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the probability column in the calibration database #\n",
    "\n",
    "cal_data_scaled.columns = ['B0', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'A1', 'A2', 'A3', 'LAI', 'FAPAR', 'FCOVER', 'subset_id', 'prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace942f-d46e-4311-a8a3-8342c0204e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign max probability in each subset to every member of that subset \n",
    "\n",
    "cal_data_scaled['prob'] = cal_data_scaled.groupby('subset_id')['prob'].transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14895acc-d0cc-4baa-8a8d-7b05002ad9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(cal_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf60ac9-7467-4822-9525-ba90663f0acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find median probability \n",
    "\n",
    "median_prob = numpy.median(cal_data_scaled['prob'])\n",
    "\n",
    "print(median_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dbe52f-c66c-4237-8b41-1eb96d1704b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set weight that are below the median to zero \n",
    "\n",
    "cal_data_scaled['prob'] = cal_data_scaled['prob'].where(cal_data_scaled['prob'] > median_prob, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ec311-ed30-40e4-aee6-9ca7ecd64793",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f0cb28-f668-4499-a9f4-70cf6d6255ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates the training and validation sets from the calibration data\n",
    "\n",
    "training_data, valid_data = sklearn.model_selection.train_test_split(cal_data_scaled, test_size=0.3, train_size=0.7, random_state=None, shuffle=True, stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9cfb6c-6c7e-4d76-8322-6f1529f91268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resets the indices in the training data so that they start from zero\n",
    "\n",
    "training_data = training_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40309ddb-1de2-49b5-85b6-2cd212cdf3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resets the indices in the validation data so that they start from zero\n",
    "\n",
    "valid_data = valid_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a5ee8c-993c-43eb-aa6a-db5151bf96e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the LAI, FAPAR, and FCOVER data to be used for training\n",
    "\n",
    "LAI_training = training_data['LAI']\n",
    "FAPAR_training = training_data['FAPAR']\n",
    "FCOVER_training = training_data['FCOVER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fba201-30f2-486d-9ada-69f5cb405097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the LAI, FAPAR, and FCOVER data to be used for validation\n",
    "\n",
    "LAI_valid = valid_data['LAI']\n",
    "FAPAR_valid = valid_data['FAPAR']\n",
    "FCOVER_valid = valid_data['FCOVER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c281f461-3065-483d-843d-e2d28cc909c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the probabilites for training and validation \n",
    "\n",
    "training_weights = numpy.array(training_data['prob'])\n",
    "valid_weights = numpy.array(valid_data['prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e9b40-8e0a-48b8-a38f-ae7fc4b4b26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gee = ['cosVZA', 'cosSZA', 'cosRAA', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8A', 'B11', 'B12']\n",
    "MatLab = ['B0', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'A1', 'A2', 'A3']\n",
    "#MatLab = ['B0', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
    "LAI_inputs = ['B3','B4', 'B5', 'B6', 'B7', 'B8A', 'B11', 'B12','cosVZA', 'cosSZA', 'cosRAA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed9d0fd-042b-4ac2-92bf-eb717d0bfd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes that isn't needed for training and validation \n",
    "# Explicitly subset the inputs\n",
    "training_data = training_data[MatLab]\n",
    "valid_data = valid_data[MatLab]\n",
    "test_data = ref_data[MatLab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77409a-56da-45a8-ad93-d8a5213bef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80cd0cf-042e-4c99-8604-ea963fc16d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ed162-ec16-4428-9c51-821746dfb822",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAI_callback = tensorflow.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c0fb5-f390-42b8-8c73-c5bc2cbe2012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the Neural Network models for LAI, FAPAR, and FCOVER \n",
    "\n",
    "LAI_model = tensorflow.keras.models.Sequential([\n",
    "    tensorflow.keras.layers.Dense(10, activation=tensorflow.nn.relu, \n",
    "                                  input_shape=[len(training_data.keys())]),\n",
    "    tensorflow.keras.layers.Dense(10, activation=tensorflow.nn.relu),\n",
    "    tensorflow.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "LAI_model.compile(\n",
    "    optimizer=tensorflow.keras.optimizers.Nadam(),\n",
    "    loss='mse',\n",
    "    metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ec20cb-0821-4103-a9fa-b04112293d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs NN Model for LAI\n",
    "\n",
    "LAI_history = LAI_model.fit(x = numpy.array(training_data), y = numpy.array(LAI_training), \n",
    "                            sample_weight = training_weights,\n",
    "                            epochs = 120,\n",
    "                            validation_data = (numpy.array(valid_data), numpy.array(LAI_valid), valid_weights),\n",
    "                            callbacks=[LAI_callback]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f987f14b-89e0-4aa3-bbeb-a824ebbc40c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LAI_model.save('./models/LAI_models_no_angles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c072df-03d0-4b38-b1d5-6791314ff516",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(cal_data_scaled['A1']))\n",
    "print(min(cal_data_scaled['A1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d13c744-0f60-4882-bb89-2a950b619874",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(cal_data_scaled['A2']))\n",
    "print(min(cal_data_scaled['A2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cb9460-a53d-49fd-a614-d25a34d2634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(cal_data_scaled['A3']))\n",
    "print(min(cal_data_scaled['A3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47b1a29-d15c-4206-9201-e4edb1af1b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes predictions on the validation data\n",
    "\n",
    "LAI_predictions = pandas.Series(LAI_model.predict(numpy.array(test_data)).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922822e3-2bca-412f-b862-f7fdcf77f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that creates the density plots \n",
    "\n",
    "def plotting_function(var, input_var, resp_var, title, xlabel, ylabel, alg, ax=None):\n",
    "    ax = ax\n",
    "    input_var = input_var*cal_data[var].std() + cal_data[var].mean()\n",
    "    resp_var = resp_var*cal_data[var].std() + cal_data[var].mean()\n",
    "    xy = numpy.vstack([input_var, resp_var])\n",
    "    z = scipy.stats.gaussian_kde(xy)(xy)\n",
    "    idx = z.argsort()\n",
    "    x = input_var[idx]\n",
    "    y = resp_var[idx]\n",
    "    z = z[idx]\n",
    "    rmse = sklearn.metrics.mean_squared_error(x, y, squared=False)\n",
    "    r_sqr = sklearn.metrics.r2_score(x, y)\n",
    "    ax.scatter(x, y, c = z)\n",
    "    plt.colorbar(mappable=ax.scatter(x, y, c = z), ax=ax)\n",
    "    ax.set_title(title + '-' + alg + ' - RMSE: {}'.format(rmse) + ' - $R^2$: {}'.format(r_sqr))\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab5631a-9c52-4be4-98e8-db222eace5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAI_test = ref_data['LAI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed34b9e-1b72-4a31-a3b1-8bfb6265d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1,1,figsize=(25,15))\n",
    "\n",
    "plotting_function('LAI', LAI_test, LAI_predictions, 'LAI','Input LAI','Predicted LAI','NNet', ax1)\n",
    "  \n",
    "fig.suptitle('Predict on Random Testing Set', fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
